{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aad5abc8",
   "metadata": {},
   "source": [
    "# Reading in the data\n",
    "\n",
    "Here I will use the popular library \"pandas\" to import and store the data in a DataFrame. DataFrames are extremely powerful for exploratory data analysis like this because they allow for intricate queries to run. Once I have finished cleaning the data, I will output it to a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f50d632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3a4ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/the_office_lines_scripts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1371154",
   "metadata": {},
   "source": [
    "### Cleaning the 'speaker' data \n",
    "\n",
    "Every task has the speaker (IE the character speaking) at its core. Unfortunately, the speaker data from the .csv file that I have is riddled with typos and lacks a consistent format. I will take a multi-step approach to combat this.\n",
    "\n",
    "#### Removing common punctuation\n",
    "\n",
    "Upon examining the data, I found that several punctuating marks were very common. However, these marks are not used consistently and will cause groupings to fail as we continue through the project. In order to prevent this, I will standardize to data by removing the most common punctuating marks which are not used to delimit multiple characters\n",
    "\n",
    "#### Correcting obvious misspellings\n",
    "\n",
    "The spelling of character names is remarkably inconsistent in the provided script. For example, there are at least 10 different spellings of the name \"Michael\" -- again, this will cause groupings to fail. So, I will map the obvious ones to their correct spelling.\n",
    "\n",
    "* Note here that some misspellings are less clear, for example- is \"Helen\" meant to be \"Helene\" or is there actually a side character named \"Helen\"?\n",
    "* In the interest of time, I have opted to ignore any misspellings which require context and focus on the most obvious ones only\n",
    "\n",
    "\n",
    "#### Split apart multiple speakers\n",
    "\n",
    "This dataset does not split lines into a single speaker. The impact of this is that if \"Michael/Dwight\" say something together, then that would get filed separately from \"Michael\" or \"Dwight\". In reality, we want one speaker per row. So, I will split apart based on all the delimiters I can find in the data\n",
    "\n",
    "#### Pull known speakers from the wiki article\n",
    "\n",
    "Since the speaker data is both extremely messy and extremely important, we may reduce the number of errors by cross-referencing it with the known characters from the office wiki page:\n",
    "https://en.wikipedia.org/wiki/List_of_The_Office_(American_TV_series)_characters\n",
    "\n",
    "Ultimately, on account of time constraints I will not attempt to manually correct every instance in the data where a character does not match the known character list. Instead, I will take the steps listed above and perform an exclusive join to the list of known characters, effectively erasing any lines by unknown characters\n",
    "\n",
    "#### Cross reference with others who have done similar projects\n",
    "\n",
    "Finally, I will search the web to find others who have performed data cleanup on this dataset and cross-reference my work with theirs to see how it compares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc37dd60",
   "metadata": {},
   "source": [
    "#### Normalize casing + remove common punctuation\n",
    "\n",
    "Upon examining the data, I found that several punctuating marks were very common. However, these marks are not used consistently and will cause groupings to fail as we continue through the project. In order to prevent this, I will standardize to data by removing the most common punctuating marks which are not used to delimit multiple characters.\n",
    "\n",
    "In addition, I will normalize the casing to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce773a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_common_punctuation(speaker: str):\n",
    "    return speaker.lower().replace('.','').replace(\"'\", '').replace(\":\", '')\n",
    "\n",
    "df['speaker'] = df['speaker'].apply(remove_common_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26380684",
   "metadata": {},
   "source": [
    "#### Correcting obvious misspellings\n",
    "\n",
    "The spelling of character names is remarkably inconsistent in the provided script. For example, there are at least 10 different spellings of the name \"Michael\" -- again, this will cause groupings to fail. So, I will map the obvious ones to their correct spelling.\n",
    "\n",
    "* Note here that some misspellings are less clear, for example- is \"Helen\" meant to be \"Helene\" or is there actually a side character named \"Helen\"?\n",
    "* In the interest of time, I have opted to ignore any misspellings which require context and focus on the most obvious ones only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04c8332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_speaker_misspellings(speaker: str):\n",
    "    spelling_map = {\n",
    "        \"chares\": \"charles\",\n",
    "        \"anglea\": \"angela\",\n",
    "        \"carrol\": \"carol\",\n",
    "        \"carroll\": \"carol\",\n",
    "        \"dacvid\": \"david\",\n",
    "        \"walalace\": \"wallace\",\n",
    "        \"wallcve\": \"wallace\",\n",
    "        \"deagnelo\": \"deangelo\",\n",
    "        \"denagelo\": \"deangelo\",\n",
    "        \"dwightkschrute\": \"dwight\",\n",
    "        \"michae\": \"michael\",\n",
    "        \"micael\": \"michael\",\n",
    "        \"micahel\": \"michael\",\n",
    "        \"michaels ad\": \"michael\",\n",
    "        \"michal\": \"michael\",\n",
    "        \"micheal\": \"michael\",\n",
    "        \"michel\": \"michael\",\n",
    "        \"mihael\": \"michael\",\n",
    "        \"miichael\": \"michael\",\n",
    "        \"michaell\": \"michael\",\n",
    "        \"todd packer\": \"todd\",\n",
    "        \"phylis\": \"phyllis\",\n",
    "        \"phyliss\": \"phyllis\",\n",
    "        \"phylliss\": \"phyllis\",\n",
    "    }\n",
    "    for i in spelling_map:\n",
    "        speaker = re.sub(fr\"\\b{i}\\b\", spelling_map[i], speaker)\n",
    "    return speaker\n",
    "df['speaker'] = df.speaker.apply(correct_speaker_misspellings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a59679",
   "metadata": {},
   "source": [
    "#### Split apart multiple speakers\n",
    "\n",
    "This dataset does not split lines into a single speaker. The impact of this is that if \"Michael/Dwight\" say something together, then that would get filed separately from \"Michael\" or \"Dwight\". In reality, we want one speaker per row. So, I will split apart based on all the delimiters I can find in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db3c4241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_speakers(speaker: str):\n",
    "    speaker = re.sub(r\"\\[.+\\]\", '', speaker)\n",
    "    delimiter = '######'\n",
    "    split_delimiters = [', and ', ',', ' and ', ' & ', '/', ' ,']\n",
    "    for i in split_delimiters:\n",
    "        speaker = speaker.replace(i,  delimiter).strip(' ')\n",
    "    return speaker.split(delimiter)\n",
    "\n",
    "df['speaker'] = df.speaker.apply(split_speakers)\n",
    "df = df.explode('speaker').reset_index(drop=True)\n",
    "df['speaker'] = df.speaker.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb81820",
   "metadata": {},
   "source": [
    "#### Pull known speakers from the wiki article\n",
    "\n",
    "Since the speaker data is both extremely messy and extremely important, we may reduce the number of errors by cross-referencing it with the known characters from the office wiki page:\n",
    "https://en.wikipedia.org/wiki/List_of_The_Office_(American_TV_series)_characters\n",
    "\n",
    "In order to generate this list, I opted to manually copy + paste + clean the data. I could have considered a script to do this, but it would have had diminishing returns compared to a simple vim macro.\n",
    "\n",
    "Ultimately, on account of time constraints I will not attempt to manually correct every instance in the data where a character does not match the known character list. Instead, I will take the steps listed above and perform an exclusive join to the list of known characters, effectively erasing any lines by unknown characters\n",
    "\n",
    "Here are the characters mentioned in the wiki:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a08632",
   "metadata": {},
   "source": [
    "1. Michael Scott\n",
    "1. Dwight Schrute\n",
    "1. Jim Halpert\n",
    "1. Pam Beesly\n",
    "1. Ryan Howard\n",
    "1. Andy Bernard\n",
    "1. Robert California\n",
    "1. Stanley Hudson\n",
    "1. Kevin Malone\n",
    "1. Meredith Palmer\n",
    "1. Angela Martin\n",
    "1. Oscar Martinez\n",
    "1. Phyllis Vance\n",
    "1. Roy Anderson\n",
    "1. Jan Levinson\n",
    "1. Toby Flenderson\n",
    "1. Kelly Kapoor\n",
    "1. Creed Bratton\n",
    "1. Darryl Philbin\n",
    "1. Erin Hannon\n",
    "1. Gabe Lewis\n",
    "1. Holly Flax\n",
    "1. Nellie Bertram\n",
    "1. Clark Green\n",
    "1. Pete Miller\n",
    "1. David Wallace\n",
    "1. Deangelo Vickers\n",
    "1. Jo Bennett\n",
    "1. Josh Porter\n",
    "1. Charles Miner\n",
    "1. Ed Truck\n",
    "1. Dan Gore\n",
    "1. Craig\n",
    "1. Troy Underbridge\n",
    "1. Karen Filippelli\n",
    "1. Danny Cordray\n",
    "1. A.J.\n",
    "1. Ben Nugent\n",
    "1. Todd Packer\n",
    "1. Cathy Simms\n",
    "1. Hunter\n",
    "1. Rolando\n",
    "1. Stephanie\n",
    "1. Jordan Garfield\n",
    "1. Ronni\n",
    "1. Lonny Collins\n",
    "1. Madge Madsen\n",
    "1. Glenn\n",
    "1. Jerry DiCanio\n",
    "1. Phillip\n",
    "1. Michael\n",
    "1. Matt\n",
    "1. Hidetoshi Hasagawa\n",
    "1. Gary Trundell\n",
    "1. Val Johnson\n",
    "1. Nate Nickerson\n",
    "1. Gideon\n",
    "1. Bruce\n",
    "1. Frank\n",
    "1. Louanne Kelley\n",
    "1. Devon White\n",
    "1. Kendall\n",
    "1. Sadiq\n",
    "1. Nick\n",
    "1. Tony Gardner\n",
    "1. Martin Nash\n",
    "1. Hannah Smoterich-Barr\n",
    "1. Fred Henry\n",
    "1. Merv Bronte\n",
    "1. Finger Lakes Guy\n",
    "1. Miserly Man\n",
    "1. Carol Stills \n",
    "1. Donna Newton \n",
    "1. Lucas \"Luke\" Cooper\n",
    "1. Gerald Halpert\n",
    "1. Betsy Halpert\n",
    "1. Thomas Halpert \n",
    "1. Peter Halpert \n",
    "1. Katy Moore\n",
    "1. Helene Beesly \n",
    "1. William Beesly\n",
    "1. Penny Beesly\n",
    "1. Sylvia / Meemaw\n",
    "1. Alex\n",
    "1. Isabel Poreba\n",
    "1. Cecelia Marie \"CeCe\" Halpert\n",
    "1. Philip Halpert\n",
    "1. Mose Schrute\n",
    "1. Fannie Schrute \n",
    "1. Jeb Schrute \n",
    "1. Cameron Whitman \n",
    "1. Zeke Schrute \n",
    "1. Shirley\n",
    "1. Heinrich Manheim \n",
    "1. Henry Bruegger \n",
    "1. Esther Bruegger \n",
    "1. Rolf Ahl \n",
    "1. Trevor Bortmen \n",
    "1. Melvina Whitaker\n",
    "1. Ira Glicksberg \n",
    "1. Gabor Csupczyk \n",
    "1. Wolf von \n",
    "1. Robert Lipton \n",
    "1. Phillip Halsted Schrute\n",
    "1. Bandit (garbage, cat)\n",
    "1. Rachael Martin\n",
    "1. Walter Bernard, Sr.\n",
    "1. Ellen Bernard\n",
    "1. Walter Bernard, Jr.\n",
    "1. Jessica\n",
    "1. Reed\n",
    "1. Irene\n",
    "1. Glenn\n",
    "1. Jada Philbin\n",
    "1. Justine\n",
    "1. Gwyneth Philbin\n",
    "1. Stacey\n",
    "1. Lynn\n",
    "1. Gil\n",
    "1. Ravi\n",
    "1. Melissa Hudson \n",
    "1. Terri Hudson \n",
    "1. Cynthia\n",
    "1. Robert \"Bob\" Vance\n",
    "1. Elbert Lapin\n",
    "1. Jake Palmer \n",
    "1. Sasha Flenderson \n",
    "1. Rory Flenderson \n",
    "1. Kathy Becker (never appears)\n",
    "1. Art Gould \n",
    "1. Astrid Levinson\n",
    "1. Kenny Anderson \n",
    "1. Lara\n",
    "1. Dan\n",
    "1. Mr. Flax\n",
    "1. Mrs. Flax\n",
    "1. Rachel Wallace \n",
    "1. Teddy Wallace \n",
    "1. Hank Tate\n",
    "1. Billy Merchant\n",
    "1. Leo\n",
    "1. Gino\n",
    "1. Brenda Matlowe\n",
    "1. Vikram\n",
    "1. Al Brown\n",
    "1. Elizabeth\n",
    "1. Fern Widgale\n",
    "1. The Prince Family\n",
    "1. Brandon\n",
    "1. Justin Spitzer\n",
    "1. Megan\n",
    "1. Deborah Shoshlefski\n",
    "1. Tom Witochkin\n",
    "1. The Scranton Strangler (never appears)\n",
    "1. Gordon\n",
    "1. The documentary film crew\n",
    "1. Brian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1be1f2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from known_characters import known_characters\n",
    "known_character_set = set(known_characters)\n",
    "df = df[df.speaker.apply(lambda x: x in known_character_set)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426d93fd",
   "metadata": {},
   "source": [
    "#### Cross reference with others who have done similar projects\n",
    "\n",
    "After searching the web I found someone else who did something similar. His work is available for free on github in this repo: https://github.com/brianbuie/the-office\n",
    "\n",
    "Pulling it into a DataFrame and manually inspecting it shows that my work is pretty similar. I will also cross-reference it when performing the tasks to see whether there are any differences which might warrant close investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9eb7f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from external_the_office_cleaned_lines import cleaned_lines\n",
    "records = []\n",
    "\n",
    "for i in cleaned_lines:\n",
    "    season= i['season']\n",
    "    episode = i['episode']\n",
    "    title = i['title']\n",
    "    for index,scene in enumerate(i['scenes'] + i['deleted_scenes']):\n",
    "        for line in scene:\n",
    "            speaker = line['character']\n",
    "            line_text = line['line']\n",
    "            records.append({\n",
    "                \"season\": season,\n",
    "                \"episode\": episode,\n",
    "                \"title\": title,\n",
    "                \"scene\": index + 1,\n",
    "                \"speaker\": speaker,\n",
    "                \"line_text\": line_text,\n",
    "            })\n",
    "external_df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c45285a",
   "metadata": {},
   "source": [
    "### Save to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3992502e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/cleaned_office_data.csv', index=False)\n",
    "external_df.to_csv('../data/cleaned_external_office_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
